{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'LUCAS_Self_ViT_trans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_SimCLR_utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset_loader import SNDataset,SNDatasetClimate, myNormalize, myToTensor, Augmentations\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "from dataset.utils.utils import TextColors as tc\n",
    "from plot_utils.plot import plot_train_test_losses\n",
    "from datetime import date, datetime\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'LUCAS' # 'LUCAS', 'RaCA'\n",
    "\n",
    "if DATASET == 'LUCAS':\n",
    "    from dataset.dataset_loader import SNDataset,SNDatasetClimate, myNormalize, myToTensor, Augmentations\n",
    "    OC_MAX = 87\n",
    "if DATASET == 'RaCA':\n",
    "    from dataset.dataset_loader import SNDataset,SNDatasetClimate, myNormalize, myToTensor, Augmentations\n",
    "    OC_MAX = 4115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder called 'results' in the current directory if it doesn't exist\n",
    "if not os.path.exists('results_simclr_lucas'):\n",
    "    os.mkdir('results_simclr_lucas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date and Time: 2024-02-26 13:18:06\n"
     ]
    }
   ],
   "source": [
    "# Format the date and time\n",
    "now = datetime.now()\n",
    "start_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"Current Date and Time:\", start_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nafiseh'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "NAFISEH = \"Nafiseh\"\n",
    "MOIEN = \"Moien\"\n",
    "\n",
    "if \"d:\" in os.getcwd():\n",
    "    USER = MOIEN\n",
    "elif \"c:\" in os.getcwd():\n",
    "    USER = NAFISEH\n",
    "else:\n",
    "    raise Exception(\"Unknown user\")\n",
    "\n",
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "NUM_WORKERS = 6 if USER == NAFISEH else 2\n",
    "TRAIN_BATCH_SIZE = 32 if USER == NAFISEH else 4\n",
    "TEST_BATCH_SIZE = 32 if USER == NAFISEH else 4\n",
    "LEARNING_RATE = 1e-4 if USER == NAFISEH else 1e-4\n",
    "NUM_EPOCHS = 30 if USER == NAFISEH else 2\n",
    "LR_SCHEDULER = \"step\" # step, plateau or None\n",
    "\n",
    "USE_SRTM = True\n",
    "\n",
    "USE_SPATIAL_ATTENTION = False if USER == NAFISEH else False\n",
    "CNN_ARCHITECTURE = 'ViT' # vgg16 or resnet101 or \"ViT\"\n",
    "RNN_ARCHITECTURE = 'Transformer' # LSTM, GRU, RNN, Transformer\n",
    "REG_VERSION = 1 if USER == NAFISEH else 2\n",
    "USE_LSTM_BRANCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if USE_SRTM:\n",
    "    mynorm = myNormalize(img_bands_min_max =[[(0,7),(0,1)], [(7,12),(-1,1)], [(12), (-4,2963)], [(13), (0, 90)]], oc_min = 0, oc_max = OC_MAX)\n",
    "else:\n",
    "    mynorm = myNormalize(img_bands_min_max =[[(0,7),(0,1)], [(7,12),(-1,1)]], oc_min = 0, oc_max = OC_MAX)\n",
    "    \n",
    "my_to_tensor = myToTensor()\n",
    "my_augmentation = Augmentations()\n",
    "train_transform = transforms.Compose([mynorm, my_to_tensor,my_augmentation])\n",
    "test_transform = transforms.Compose([mynorm, my_to_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LUCAS Dataset, we had two different random samples with the same numbering system. In the following we changed the names of one of them. Then we combine the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Specify the directory containing the images\n",
    "# source_directory = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images_simclr_LUCAS\"\n",
    "\n",
    "# # Specify the destination directory for the renamed files\n",
    "# destination_directory = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Renamed_l8_images_simclr_LUCAS\"\n",
    "\n",
    "# # Create the destination directory if it doesn't exist\n",
    "# if not os.path.exists(destination_directory):\n",
    "#     os.makedirs(destination_directory)\n",
    "\n",
    "# # Loop through all files in the source directory\n",
    "# for filename in os.listdir(source_directory):\n",
    "#     # Split the filename on the underscore\n",
    "#     parts = filename.split(\"_\")\n",
    "#     if parts[0].startswith(\"100\"):\n",
    "#         # Replace the first character '1' with '5' and ensure the rest of the number remains unchanged\n",
    "#         new_number = '5' + parts[0][1:]\n",
    "#         # Construct the new filename\n",
    "#         new_filename = f\"{new_number}_{parts[1]}\"\n",
    "        \n",
    "#         # Construct the full old file path and new file path\n",
    "#         old_file = os.path.join(source_directory, filename)\n",
    "#         new_file = os.path.join(destination_directory, new_filename)\n",
    "        \n",
    "#         # Rename and move the file by changing its path\n",
    "#         os.rename(old_file, new_file)\n",
    "#         print(f\"Moved and renamed '{old_file}' to '{new_file}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Specify the source directory containing the CSV files\n",
    "# source_directory = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_large\\\\filled\"\n",
    "# # Specify the destination directory for the updated CSV files\n",
    "# destination_directory = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_large\\\\Renamed_filled\"\n",
    "\n",
    "# # Create the destination directory if it doesn't exist\n",
    "# if not os.path.exists(destination_directory):\n",
    "#     os.makedirs(destination_directory)\n",
    "\n",
    "# # Loop through all files in the source directory\n",
    "# for filename in os.listdir(source_directory):\n",
    "#     # Check if the file is a CSV file\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         # Construct the full file path\n",
    "#         file_path = os.path.join(source_directory, filename)\n",
    "        \n",
    "#         # Read the CSV file into a DataFrame\n",
    "#         df = pd.read_csv(file_path)\n",
    "        \n",
    "#         # Check if 'PointID' column exists in the DataFrame\n",
    "#         if 'Point_ID' in df.columns:\n",
    "#             # Update 'PointID' values from '100XXXXX' to '500XXXXX'\n",
    "#             df['Point_ID'] = df['Point_ID'].apply(lambda x: '500' + str(x)[3:] if str(x).startswith('100') else x)\n",
    "            \n",
    "#             # Construct the full path for the updated file\n",
    "#             updated_file_path = os.path.join(destination_directory, filename)\n",
    "            \n",
    "#             # Write the updated DataFrame to a new CSV file in the destination directory\n",
    "#             df.to_csv(updated_file_path, index=False)\n",
    "#             print(f\"Updated file saved to '{updated_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination part is as following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the paths to the two folders\n",
    "# folder1 = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\All\\\\filled'\n",
    "# folder2 = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_large\\\\Renamed_filled'\n",
    "\n",
    "# # Define the path to the destination folder where you want to save the appended files\n",
    "# destination_folder = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\LUCAS_SimCLR\"\n",
    "\n",
    "# # Create the destination folder if it doesn't exist\n",
    "# if not os.path.exists(destination_folder):\n",
    "#     os.makedirs(destination_folder)\n",
    "\n",
    "# # Iterate over the CSV files in the first folder\n",
    "# for filename in os.listdir(folder1):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         file1_path = os.path.join(folder1, filename)\n",
    "#         file2_path = os.path.join(folder2, filename)\n",
    "        \n",
    "#         # Check if the counterpart exists in the second folder\n",
    "#         if os.path.exists(file2_path):\n",
    "#             # Read both CSV files\n",
    "#             df1 = pd.read_csv(file1_path)\n",
    "#             df2 = pd.read_csv(file2_path)\n",
    "            \n",
    "#             # Append df2 to df1\n",
    "#             appended_df = df1.append(df2, ignore_index=True)\n",
    "            \n",
    "#             # Define the path for the appended CSV in the destination folder\n",
    "#             destination_file_path = os.path.join(destination_folder, filename)\n",
    "            \n",
    "#             # Save the appended DataFrame to the destination folder\n",
    "#             appended_df.to_csv(destination_file_path, index=False)\n",
    "#             print(f\"Appended file saved as '{destination_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the samples id: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df1 = pd.read_csv(\"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\simclr\\\\simclr.csv\")\n",
    "# df2 = pd.read_csv(\"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\simclr\\\\simclr_LUCAS_large.csv\")\n",
    "\n",
    "# df2['Point_ID'] = df2['Point_ID'].apply(lambda x: '500' + str(x)[3:] if str(x).startswith('100') else x)\n",
    "\n",
    "# # Append df2 to df1\n",
    "# appended_df = df1.append(df2, ignore_index=True)\n",
    "\n",
    "# # Define the path for the output file where you want to save the appended result\n",
    "# output_file_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\simclr\\\\LUCAS_SimCLR_1.csv'\n",
    "\n",
    "# # Save the appended DataFrame to a new CSV file\n",
    "# appended_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# print(f\"Appended data saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check wether there is corrupted image file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import io\n",
    "# import os\n",
    "\n",
    "# folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images\\\\train'\n",
    "\n",
    "# # Iterate over files in the folder\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     # Construct the full path to each image file\n",
    "#     file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "#     try:\n",
    "#         # Load the image\n",
    "#         l8_img = io.imread(file_path)\n",
    "#         # Process the loaded image or perform any other operations\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading image {file_path}: {e}\")\n",
    "#         # Handle the error or skip the file if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check any mismatch between ids of images and climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Path to the folder containing the files\n",
    "# folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images'\n",
    "\n",
    "# # Path to the CSV file\n",
    "# csv_file_path = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_Cleaned\\\\_soil.csv\"\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# # Extract the Point_ID column (ensure the column name matches exactly)\n",
    "# point_ids = df['Point_ID'].unique()\n",
    "\n",
    "# # List to hold the first part of filenames\n",
    "# filename_parts = []\n",
    "\n",
    "# # Loop through all files in the directory\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if \"_\" in filename:  # Check if filename contains an underscore\n",
    "#         part = filename.split(\"_\")[0]  # Split the filename and take the first part\n",
    "#         filename_parts.append(part)\n",
    "\n",
    "# # Convert filename_parts to a set for faster lookup\n",
    "# filename_parts_set = set(filename_parts)\n",
    "\n",
    "# # Check each Point_ID against the filename parts\n",
    "# for point_id in point_ids:\n",
    "#     if str(point_id) not in filename_parts_set:\n",
    "#         print((point_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omit any mismatch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Directories for your files\n",
    "# image_dir = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images'\n",
    "# csv_dir = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR\\\\\"\n",
    "# clean_csv_dir = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_Cleaned\\\\\"\n",
    "\n",
    "# # Ensure the clean CSV directory exists\n",
    "# os.makedirs(clean_csv_dir, exist_ok=True)\n",
    "\n",
    "# # List all image filenames and extract Point_IDs\n",
    "# image_files = os.listdir(image_dir)\n",
    "# image_point_ids = set(int(f.split('_')[0]) for f in image_files if f.endswith('.tif'))\n",
    "\n",
    "# # Process each CSV file individually\n",
    "# for csv_file in os.listdir(csv_dir):\n",
    "#     if csv_file.endswith('.csv'):\n",
    "#         # Load the current CSV file\n",
    "#         csv_path = os.path.join(csv_dir, csv_file)\n",
    "#         df = pd.read_csv(csv_path)\n",
    "\n",
    "#         # # Check for missing values\n",
    "#         # if df.isnull().values.any():\n",
    "#         #     # Report the presence of missing values\n",
    "#         #     print(f\"Missing values found in {csv_file}:\")\n",
    "#         #     print(df.isnull().sum())\n",
    "\n",
    "#             # Optional: Handle missing values here (e.g., drop, fill, etc.)\n",
    "#             # df = df.dropna()  # Example: Remove rows with missing values\n",
    "#             # df.fillna(0, inplace=True)  # Example: Fill missing values with 0\n",
    "\n",
    "#         # Filter out rows where Point_ID is not in image_point_ids\n",
    "#         filtered_df = df[df['Point_ID'].isin(image_point_ids)]\n",
    "\n",
    "#         # Save the filtered DataFrame to a new file in the clean_csv_dir\n",
    "#         clean_csv_path = os.path.join(clean_csv_dir, csv_file)\n",
    "#         filtered_df.to_csv(clean_csv_path, index=False)\n",
    "\n",
    "#         print(f\"Filtered {csv_file} saved to {clean_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USER == MOIEN:\n",
    "    train_l8_folder_path = 'D:\\python\\SoilNet\\dataset\\l8_images\\\\train\\\\'\n",
    "    test_l8_folder_path = 'D:\\python\\SoilNet\\dataset\\l8_images\\\\test\\\\'\n",
    "    val_l8_folder_path = 'D:\\python\\SoilNet\\dataset\\l8_images\\\\val\\\\'\n",
    "    testval_l8_folder_path = 'D:\\python\\SoilNet\\dataset\\l8_images\\\\val\\\\'\n",
    "    lucas_csv_path = 'D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv'\n",
    "    climate_csv_folder_path = \"D:\\\\python\\\\SoilNet\\\\dataset\\\\Climate\\\\All\\\\filled\\\\\"\n",
    "\n",
    "\n",
    "elif USER == NAFISEH:\n",
    "\n",
    "    if DATASET == 'LUCAS':\n",
    "     train_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images\\\\train'\n",
    "     test_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images\\\\test'\n",
    "     val_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images\\\\val'\n",
    "     testval_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images\\\\val'\n",
    "     # lucas_csv_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\LUCAS_2015_all.csv'\n",
    "    #  lucas_csv_path = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\simclr\\\\simclr.csv\" # The LUCAS will be replaced by SimCLR file\n",
    "     lucas_csv_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\simclr\\\\LUCAS_SimCLR_1.csv'\n",
    "     # climate_csv_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\All\\\\filled'\n",
    "     climate_csv_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_Cleaned'\n",
    "\n",
    "\n",
    "    # if DATASET == 'RaCA':\n",
    "    #  train_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images_simclr_RaCA\\\\train'\n",
    "    #  test_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images_simclr_RaCA\\\\test'\n",
    "    #  val_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images_simclr_RaCA\\\\val'\n",
    "    #  testval_l8_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\l8_images_simclr_RaCA\\\\test_val'\n",
    "    #  # lucas_csv_path = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\RapidCarbon_OC.csv\"\n",
    "    #  lucas_csv_path = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\simclr\\\\simclr_RaCA.csv\"\n",
    "    #  climate_csv_folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\RaCA_SimCLR\\\\filled'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'OC' column should always have a value or the dataloader would face a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Directory containing the CSV files\n",
    "# csv_dir = \"C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_Cleaned\\\\\"\n",
    "\n",
    "# # Iterate over each CSV file in the directory\n",
    "# for csv_file in os.listdir(csv_dir):\n",
    "#     if csv_file.endswith('.csv'):\n",
    "#         # Construct the full path to the current CSV file\n",
    "#         csv_path = os.path.join(csv_dir, csv_file)\n",
    "        \n",
    "#         # Read the CSV into a DataFrame\n",
    "#         df = pd.read_csv(csv_path)\n",
    "        \n",
    "#         # Check if 'OC' column exists to avoid KeyError\n",
    "#         if 'OC' in df.columns:\n",
    "#             # Replace missing values in 'OC' column with 0\n",
    "#             df['OC'].fillna(0, inplace=True)\n",
    "            \n",
    "#             # Save the modified DataFrame back to the original CSV, overwriting it\n",
    "#             df.to_csv(csv_path, index=False)\n",
    "            \n",
    "#             print(f\"Modified '{csv_file}' has been overwritten with the updated 'OC' column values.\")\n",
    "#         else:\n",
    "#             print(f\"'OC' column not found in {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [0,1,2,3,4,5,6,7,8,9,10,11] if not USE_SRTM else [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "\n",
    "################################# IF Not USE_LSTM_BRANCH ###############################\n",
    "if not USE_LSTM_BRANCH: # NOT USING THE CLIMATE DATA\n",
    "\n",
    "    train_ds = SNDataset(train_l8_folder_path, lucas_csv_path,l8_bands=bands, transform=train_transform)\n",
    "    test_ds =  SNDataset(test_l8_folder_path, lucas_csv_path,l8_bands=bands, transform=test_transform)\n",
    "    val_ds = SNDataset(val_l8_folder_path, lucas_csv_path,l8_bands=bands, transform=test_transform)\n",
    "    test_ds_w_id =  SNDataset(test_l8_folder_path, lucas_csv_path,l8_bands=bands, transform=test_transform, return_point_id=True)\n",
    "    testval_ds_w_id =  SNDataset(testval_l8_folder_path, lucas_csv_path,l8_bands=bands, transform=test_transform, return_point_id=True)\n",
    "    \n",
    "################################### IF USE_LSTM_BRANCH #################################\n",
    "else: # USING THE CLIMATE DATA\n",
    "    train_ds = SNDatasetClimate(train_l8_folder_path,\n",
    "                                    lucas_csv_path,\n",
    "                                    climate_csv_folder_path,\n",
    "                                    l8_bands=bands, transform=train_transform)\n",
    "\n",
    "    test_ds = SNDatasetClimate(test_l8_folder_path,\n",
    "                                lucas_csv_path,\n",
    "                                climate_csv_folder_path,\n",
    "                                l8_bands=bands, transform=test_transform)\n",
    "    \n",
    "    val_ds = SNDatasetClimate(val_l8_folder_path,\n",
    "                                lucas_csv_path,\n",
    "                                climate_csv_folder_path,\n",
    "                                l8_bands=bands, transform=test_transform)\n",
    "    \n",
    "    test_ds_w_id = SNDatasetClimate(test_l8_folder_path,\n",
    "                                lucas_csv_path,\n",
    "                                climate_csv_folder_path,\n",
    "                                l8_bands=bands, transform=test_transform, return_point_id=True)\n",
    "\n",
    "    testval_ds_w_id = SNDatasetClimate(testval_l8_folder_path,\n",
    "                                lucas_csv_path,\n",
    "                                climate_csv_folder_path,\n",
    "                                l8_bands=bands, transform=test_transform, return_point_id=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN = test_ds_w_id[0][0][1].shape[0]\n",
    "SEQ_LEN # max sequence length for Transformer model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUNTING the csv files in the csv folder\n",
    "CSV_FILES = [f for f in os.listdir(climate_csv_folder_path) if f.endswith('.csv')]\n",
    "NUM_CLIMATE_FEATURES = len(CSV_FILES)\n",
    "NUM_CLIMATE_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__name__: submodules.src.transformer.transformer\n"
     ]
    }
   ],
   "source": [
    "from soilnet.soil_net import SoilNet, SoilNetLSTM, SoilNetSimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dl = DataLoader(train_ds, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "# # Get image and label from custom DataLoader\n",
    "# img_custom, climate,label_custom = next(iter(train_dl))\n",
    "# print(f\"Image shape: {img_custom.shape} -> [batch_size, color_channels, height, width]\")\n",
    "# print(f\"Climate shape: {climate.shape} -> [batch_size, climate_channels]\")\n",
    "# print(f\"Label shape: {label_custom.shape}\")\n",
    "# img_gpu = img_custom.to(device)\n",
    "# print(img_gpu.device, img_gpu.shape)\n",
    "# print(img_gpu.shape)\n",
    "# y = model(img_gpu)\n",
    "# y.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = {\"train_loss\": [],\n",
    "                \"train_acc_top1\": [],\n",
    "                \"train_acc_top5\": [],\n",
    "                \"train_acc_mean_pos\": [],\n",
    "                \"val_loss\": [],\n",
    "                \"val_acc_top1\": [],\n",
    "                \"val_acc_top5\": [],\n",
    "                \"val_acc_mean_pos\": [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date and Time: D_2024_02_26_T_13_18\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "# Format the date and time\n",
    "now = datetime.now()\n",
    "run_name = now.strftime(\"D_%Y_%m_%d_T_%H_%M\")\n",
    "print(\"Current Date and Time:\", run_name)\n",
    "# create a folder called 'results' in the current directory if it doesn't exist\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEEDS = [75] \n",
    "SEEDS = [1]  if USER == MOIEN else [1, 4]\n",
    "# SEEDS = [1] if USER == MOIEN else [1, 4, 69, 75, 79, 128, 474, 786, 2048, 3333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;45m CROSS VAL 1 \u001b[0m\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\u001b[92m Epoch 1\n",
      "------------------------------- \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 47/1704 [00:22<13:22,  2.07it/s, Train_Loss=4.21] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Saving the model on the last epoch\u001b[39;00m\n\u001b[0;32m     27\u001b[0m save_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/RUN_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEXP_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mUSER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth.tar\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 29\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43mSimCLR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR_SCHEDULER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_model_if_mae_lower_than\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_mae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     38\u001b[0m cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc_top1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc_top1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\_Multimodal\\SoilNet-7\\SoilNet-PreRelease\\train_SimCLR_utils.py:235\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, val_dataloader, optimizer, loss_fn, epochs, lr_scheduler, save_model_path, save_model_if_mae_lower_than)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tc\u001b[38;5;241m.\u001b[39mOKGREEN,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m,tc\u001b[38;5;241m.\u001b[39mENDC)\n\u001b[1;32m--> 235\u001b[0m     train_loss,train_acc_top1, train_acc_top5, train_acc_mean_pos \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     val_loss,val_acc_top1, val_acc_top5, val_acc_mean_pos \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    240\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[0;32m    241\u001b[0m         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# 4. Print out what's happening\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\_Multimodal\\SoilNet-7\\SoilNet-PreRelease\\train_SimCLR_utils.py:114\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data_loader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m    112\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    113\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 114\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m batch \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    117\u001b[0m     loss\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\anaconda3\\envs\\pytorchGPU\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\anaconda3\\envs\\pytorchGPU\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\anaconda3\\envs\\pytorchGPU\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\anaconda3\\envs\\pytorchGPU\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\anaconda3\\envs\\pytorchGPU\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nkakhani\\anaconda3\\envs\\pytorchGPU\\lib\\site-packages\\torch\\optim\\adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    408\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_mae = 1000 # just a big number, since our data is normalized between 0 and 1, mae is between 0 and 1 too.\n",
    "best_seed = SEEDS[0]\n",
    "for idx, seed in enumerate(SEEDS):\n",
    "    print(tc.BOLD_BAKGROUNDs.PURPLE, f\"CROSS VAL {idx+1}\", tc.ENDC)\n",
    "    \n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    test_dl = DataLoader(test_ds, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    val_dl = DataLoader(val_ds, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    #model = SoilNetFC(cnn_in_channels=12, regresor_input_from_cnn=1024, hidden_size=128).to(device)\n",
    "    # architecture = \"101+GLAM\" if USE_SPATIAL_ATTENTION else \"101\"\n",
    "    if USE_LSTM_BRANCH:\n",
    "        model = SoilNetSimCLR(use_glam=USE_SPATIAL_ATTENTION, cnn_arch= CNN_ARCHITECTURE, reg_version= REG_VERSION,\n",
    "                           cnn_in_channels=len(bands), regresor_input_from_cnn=128,\n",
    "                           lstm_n_features= NUM_CLIMATE_FEATURES, lstm_n_layers= 2, lstm_out= 128,\n",
    "                           hidden_size=128, rnn_arch=RNN_ARCHITECTURE,seq_len=SEQ_LEN).to(device)\n",
    "    else:\n",
    "        model = SoilNet(use_glam=USE_SPATIAL_ATTENTION, cnn_arch = CNN_ARCHITECTURE, reg_version= REG_VERSION,\n",
    "                       cnn_in_channels=len(bands), regresor_input_from_cnn=128, hidden_size=128).to(device)\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Saving the model on the last epoch\n",
    "    save_model_path = f\"results/RUN_{EXP_NAME}_{run_name}_{USER}.pth.tar\"\n",
    "    \n",
    "    results = train(model, train_dl, test_dl, val_dl,\n",
    "                    torch.optim.Adam(model.parameters(), lr=LEARNING_RATE),\n",
    "                    SimCLR(temperature=0.5), epochs=NUM_EPOCHS, lr_scheduler=LR_SCHEDULER,\n",
    "                    save_model_path= save_model_path,\n",
    "                    save_model_if_mae_lower_than= best_mae,\n",
    "                    )\n",
    "\n",
    "    \n",
    "    cv_results['train_loss'].append(results['train_loss'])\n",
    "    cv_results['train_acc_top1'].append(results['train_acc_top1'])\n",
    "    cv_results['train_acc_top5'].append(results['train_acc_top5'])\n",
    "    cv_results['train_acc_mean_pos'].append(results['train_acc_mean_pos'])\n",
    "    cv_results['val_loss'].append(results['val_loss'])\n",
    "    cv_results['val_acc_top1'].append(results['val_acc_top1'])\n",
    "    cv_results['val_acc_top5'].append(results['val_acc_top5'])\n",
    "    cv_results['val_acc_mean_pos'].append(results['val_acc_mean_pos'])\n",
    "    \n",
    "\n",
    "    # if results['MAE'][0] < best_mae:\n",
    "    #     best_mae = results['MAE'][0]\n",
    "    #     best_seed = seed\n",
    "    #     print(tc.BOLD_BAKGROUNDs.GREEN, f\"MAE improved to {best_mae}\", tc.ENDC)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"results/RUN_{EXP_NAME}_{run_name}_{USER}_SelfSupervised.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = np.asarray(cv_results['train_acc_mean_pos'])\n",
    "val_arr = np.asarray(cv_results['val_acc_mean_pos'])\n",
    "train_arr.shape, val_arr.shape\n",
    "plot_train_test_losses(train_arr,val_arr, title=\"Average Self-Rank\", x_label=\"Epochs\", y_label=\"Rank\",\n",
    "                       min_max_bounds= True, tight_x_lim= True,\n",
    "                       train_legend = \"Train\", test_legend = \"Validation\",\n",
    "                       save_path=f\"results/RUN_{run_name}_{USER}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"results/RUN_{EXP_NAME}_{run_name}_{USER}_SelfSupervised.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = np.asarray(cv_results['train_acc_top5'])\n",
    "val_arr = np.asarray(cv_results['val_acc_top5'])\n",
    "train_arr.shape, val_arr.shape\n",
    "plot_train_test_losses(train_arr,val_arr, title=\"Top 5 Prob\", x_label=\"Epochs\", y_label=\"Top 5 Prob\",\n",
    "                       min_max_bounds= True, tight_x_lim= True,\n",
    "                       train_legend = \"Train\", test_legend = \"Validation\",\n",
    "                       save_path=f\"results/RUN_{EXP_NAME}_{run_name}_{USER}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = np.asarray(cv_results['train_acc_top1'])\n",
    "val_arr = np.asarray(cv_results['val_acc_top1'])\n",
    "train_arr.shape, val_arr.shape\n",
    "plot_train_test_losses(train_arr,val_arr, title=\"Top 1 Prob\", x_label=\"Epochs\", y_label=\"Top 1 Prob\",\n",
    "                       min_max_bounds= True, tight_x_lim= True,\n",
    "                       train_legend = \"Train\", test_legend = \"Validation\",\n",
    "                       save_path=f\"results/RUN_{EXP_NAME}_{run_name}_{USER}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END\n",
    "We change the rest if the code worked on full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the date and time\n",
    "now = datetime.now()\n",
    "finish_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"Current Date and Time:\", finish_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/RUN_{EXP_NAME}_{run_name}_{USER}.json\", \"w\") as fp:\n",
    "    json.dump(cv_results, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[\"MAE\"],cv_results['RMSE'],cv_results[\"R2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_full = {}\n",
    "cv_results_full['MAE_MEAN'] = np.mean(cv_results['MAE'])\n",
    "cv_results_full['RMSE_MEAN'] = np.mean(cv_results['RMSE'])\n",
    "cv_results_full['R2_MEAN'] = np.mean(cv_results['R2'])\n",
    "cv_results_full['MAE_MEAN'],cv_results_full['RMSE_MEAN'],cv_results_full['R2_MEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_full['USE_LSTM_BRANCH'] = USE_LSTM_BRANCH\n",
    "cv_results_full['NUM_CLIMATE_FEATURES'] = NUM_CLIMATE_FEATURES if USE_LSTM_BRANCH else None\n",
    "cv_results_full['CSV_FILES'] = CSV_FILES if USE_LSTM_BRANCH else None\n",
    "cv_results_full['NUM_WORKERS'] = NUM_WORKERS\n",
    "cv_results_full['TRAIN_BATCH_SIZE'] = TRAIN_BATCH_SIZE\n",
    "cv_results_full['TEST_BATCH_SIZE'] = TEST_BATCH_SIZE\n",
    "cv_results_full['LEARNING_RATE'] = LEARNING_RATE\n",
    "cv_results_full['NUM_EPOCHS'] = NUM_EPOCHS\n",
    "cv_results_full['LR_SCHEDULER'] = LR_SCHEDULER\n",
    "cv_results_full['CNN_ARCHITECTURE'] = CNN_ARCHITECTURE\n",
    "cv_results_full['REG_VERSION'] = REG_VERSION\n",
    "cv_results_full['USE_SPATIAL_ATTENTION'] = USE_SPATIAL_ATTENTION\n",
    "cv_results_full['Best Seed'] = best_seed\n",
    "cv_results_full['SEEDS'] = SEEDS\n",
    "cv_results_full['OC_MAX'] = OC_MAX\n",
    "cv_results_full['USE_SRTM'] = USE_SRTM\n",
    "cv_results_full['TIME'] = {\"start\": start_string, \"finish\": finish_string}\n",
    "cv_results_full['cv_results'] = cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/RUN_{EXP_NAME}_{run_name}_{USER}.json\", \"w\") as fp:\n",
    "    json.dump(cv_results_full, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ JSON FILE\n",
    "# with open(\"results/my_dict.json\", \"r\") as fp:\n",
    "#     my_dict = json.load(fp)\n",
    "\n",
    "# print(my_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Best Model\n",
    "Loading the best model from all the coross validation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint(model=model, optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE),filename=f\"results/RUN_{run_name}_{USER}.pth.tar\")\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_checkpoint(model=model, optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE),\n",
    "#                 filename='C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-5\\\\SoilNet\\\\results\\\\RUN_D_2023_06_05_T_16_02_Nafiseh.pth.tar') #LSTM \n",
    "\n",
    "# load_checkpoint(model=model, optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE),\n",
    "#                 filename='C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-5\\\\SoilNet\\\\results\\\\RUN_D_2023_06_03_T_09_41_Nafiseh.pth.tar') #GLAM \n",
    "\n",
    "# load_checkpoint(model=model, optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE),\n",
    "#                 filename='C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-5\\\\SoilNet\\\\results\\\\RUN_D_2023_06_02_T_20_57_Nafiseh.pth.tar') #Base\n",
    "\n",
    "# model.eval()\n",
    "# print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl_w_id = DataLoader(test_ds_w_id, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_step_w_id(model=model, data_loader=test_dl_w_id, loss_fn=nn.L1Loss(), verbose=False, csv_file=f\"results/RUN_{run_name}_{USER}.csv\")\n",
    "# test_step_w_id(model=model, data_loader=test_dl_w_id, loss_fn=nn.L1Loss(), verbose=False, csv_file=f\"results/onlytest_{run_name}_{USER}.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Spatial Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_SPATIAL_ATTENTION or USE_LSTM_BRANCH:\n",
    "    raise Exception(\"The Next Part of the Notebook is only available for the model with Spatial Attention and no LSTM Branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_N = 1\n",
    "\n",
    "IMG_IN_BATCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loader = BatchLoader(test_dl_w_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch_loader(BATCH_N)\n",
    "batch[0].shape, batch[1].shape, len(batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "importlib.reload(sys.modules['plot_utils'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils.plot import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if results/attention_maps folder exists if not create it\n",
    "if not os.path.exists(\"results/attention_maps\"):\n",
    "    os.makedirs(\"results/attention_maps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_ATT = False\n",
    "ALPHA = 0.4\n",
    "with torch.no_grad():\n",
    "    pid = batch[2][IMG_IN_BATCH]\n",
    "    print(\"Point Id:\", pid)\n",
    "    out = model(batch[0].to(device))\n",
    "    print(out.shape)\n",
    "    print(model.cnn.glam.local_spatial_att.att_map.shape)\n",
    "    img_rgb = batch[0][0].permute(1,2,0)[:,:,[3,2,1]].detach().cpu().numpy()\n",
    "    img_rgb = convert2uint8(normalize(img_rgb))\n",
    "    \n",
    "    att_map = model.cnn.glam.local_spatial_att.att_map\n",
    "    att_map = F.interpolate(att_map, size=(64, 64), mode='bicubic', align_corners=True)[IMG_IN_BATCH].detach().cpu().numpy()[0]\n",
    "    att_map = np.abs(att_map) if ABS_ATT else att_map\n",
    "    att_map = convert2uint8(normalize(att_map))   \n",
    "    \n",
    "    colormap = cv2.applyColorMap(att_map, cv2.COLORMAP_JET)\n",
    "    \n",
    "    img_colormaped = cv2.addWeighted(img_rgb, 1 - ALPHA, colormap, ALPHA, 0)\n",
    "\n",
    "    display_images(img_rgb, img_colormaped, [\"Image\", \"Attention Map\"], f\"Local Attention Map Visualization | Point ID: {pid}\", figsize=(10,5))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(f\"results/attention_maps/final/_{run_name}_{USER}_pid{pid}_img_lcl_colormaped.png\", cv2.cvtColor(img_colormaped, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOB_ATT_CHANNEL = 510 # ranges between 0 and 511\n",
    "with torch.no_grad():\n",
    "    pid = batch[2][IMG_IN_BATCH]\n",
    "    print(\"Point Id:\", pid)\n",
    "    out = model(batch[0].to(device))\n",
    "    print(out.shape)\n",
    "    print(model.cnn.glam.global_spatial_att.att.shape)\n",
    "    img_rgb = batch[0][0].permute(1,2,0)[:,:,[3,2,1]].detach().cpu().numpy()\n",
    "    img_rgb = convert2uint8(normalize(img_rgb))\n",
    "    \n",
    "    att_map = model.cnn.glam.global_spatial_att.att\n",
    "    att_map = F.interpolate(att_map, size=(64, 64), mode='bicubic', align_corners=True)[IMG_IN_BATCH].detach().cpu().numpy()[GLOB_ATT_CHANNEL]\n",
    "    att_map = np.abs(att_map) if ABS_ATT else att_map\n",
    "    att_map = convert2uint8(normalize(att_map))   \n",
    "    \n",
    "    colormap = cv2.applyColorMap(att_map, cv2.COLORMAP_JET)\n",
    "    \n",
    "    img_colormaped = cv2.addWeighted(img_rgb, 1 - ALPHA, colormap, ALPHA, 0)\n",
    "\n",
    "    display_images(img_rgb, img_colormaped, [\"Image\", \"Attention Map\"], f\"Global{GLOB_ATT_CHANNEL} Attention Map Visualization | Point ID: {pid}\") \n",
    "                #    figsize=(10,5), savepath=f\"results/attention_maps/final/RUN_{run_name}_{USER}_pid{pid}_glb{GLOB_ATT_CHANNEL}.png\")\n",
    "    \n",
    "    # # Save img_rgband img_colormaped as jpg files\n",
    "    # cv2.imwrite(f\"results/attention_maps/RUN_{run_name}_{USER}_pid{pid}_img_glb{GLOB_ATT_CHANNEL}_rgb.png\", cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
    "    # cv2.imwrite(f\"results/attention_maps/RUN_{run_name}_{USER}_pid{pid}_img_glb{GLOB_ATT_CHANNEL}_colormaped.png\", cv2.cvtColor(img_colormaped, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c74e58d50e1361e9a22e65e4f4b85ac48544f43f48a101259d9c47c27371742"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
