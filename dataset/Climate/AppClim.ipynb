{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def aggregate_csv_files(folder_path, output_path_template, x_values):\n",
    "\n",
    "#     \"\"\"\n",
    "#     Aggregate all .csv files in a folder into a single file for specified values of x.\n",
    "\n",
    "#     Args:\n",
    "#         folder_path (str): The path to the folder containing the .csv files.\n",
    "#         output_path (str): The path to the output file to create.\n",
    "#         x_values (list): A list of values of x to aggregate files for.\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "#     for x in x_values:\n",
    "#         csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and f.startswith(str(x))]\n",
    "#         csv_files.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "#         print(csv_files)\n",
    "#         df = pd.concat([pd.read_csv(os.path.join(folder_path, f)) for f in csv_files], ignore_index=True, axis = 0)\n",
    "#         output_path = output_path_template.format(x)  # Insert x value into output file name\n",
    "#         print(output_path)\n",
    "#         df.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "def aggregate_csv_files(folder_path, output_path_template, x_values, expected_count):\n",
    "    \"\"\"\n",
    "    Aggregate all .csv files in a folder into a single file for specified values of x.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the .csv files.\n",
    "        output_path_template (str): The path template for the output file to create. It should include a placeholder for the 'x' value.\n",
    "        x_values (list): A list of values of x to aggregate files for.\n",
    "\n",
    "    Returns:\n",
    "        aggregated_counts (dict): A dictionary mapping each 'x' value to the number of CSV files aggregated.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    aggregated_counts = {}\n",
    "\n",
    "    for x in x_values:\n",
    "        # Filter and sort CSV files based on their names\n",
    "        csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and f.startswith(str(x))]\n",
    "        csv_files.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "        # Check if the number of CSV files is correct\n",
    "        # expected_count = int(36)  # Assuming that the expected count is the 'x' value #LUCAS\n",
    "        # expected_count = int(7)  # Assuming that the expected count is the 'x' value #RaCA\n",
    "        actual_count = len(csv_files)\n",
    "\n",
    "        if actual_count != expected_count:\n",
    "            raise ValueError(f\"Error for x={x}: Expected {expected_count} CSV files, but found {actual_count}.\")\n",
    "\n",
    "        # Concatenate data from CSV files into a single DataFrame\n",
    "        df = pd.concat([pd.read_csv(os.path.join(folder_path, f)) for f in csv_files], ignore_index=True, axis=0)\n",
    "\n",
    "        # Construct the output path by inserting the 'x' value into the output file template\n",
    "        output_path = output_path_template.format(x)\n",
    "\n",
    "        # Save the aggregated DataFrame to a new CSV file\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        # Store the number of aggregated files for this 'x' in the dictionary\n",
    "        aggregated_counts[x] = actual_count\n",
    "\n",
    "    return aggregated_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aet': 34,\n",
       " 'def': 34,\n",
       " 'pdsi': 34,\n",
       " 'pet': 34,\n",
       " 'pr': 34,\n",
       " 'soil': 34,\n",
       " 'srad': 34,\n",
       " 'swe': 34,\n",
       " 'tmmn': 34,\n",
       " 'tmmx': 34,\n",
       " 'vap': 34,\n",
       " 'vpd': 34}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate'\n",
    "# folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\RaCA_SimCLR_all'\n",
    "folder_path = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\SoilNet-PreRelease\\\\dataset\\\\Climate\\\\LUCAS_SimCLR_large'\n",
    "\n",
    "# output_path_template = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\RaCA_{}.csv'\n",
    "output_path_template = 'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-7\\\\LUCAS_SimCLR_large_{}.csv'\n",
    "\n",
    "\n",
    "climate_values = ['aet', 'def', 'pdsi', 'pet', 'pr', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap', 'vpd']  # Example x values\n",
    "# x_values = ['srad']  # Example x values\n",
    "\n",
    "aggregate_csv_files(folder_path, output_path_template, climate_values, 34)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EarthEngine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
