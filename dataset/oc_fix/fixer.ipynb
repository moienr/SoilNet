{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OC_LIMIT =  87 # Images with OC over 87 will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200102'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def add_days_to_date(date_str, days=1):\n",
    "    date_obj = datetime.strptime(date_str, '%y%m%d')\n",
    "    new_date_obj = date_obj + timedelta(days=days)\n",
    "    return new_date_obj.strftime('%y%m%d')\n",
    "\n",
    "add_days_to_date('200101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('LUCAS_2015_all.csv')\n",
    "\n",
    "# Remove rows where the value in the \"oc\" column is larger than 87\n",
    "below_87_df = df[df['OC'] <= OC_LIMIT]\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "below_87_df.to_csv('LUCAS_2015_all_87.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1 = [9.7, 19.3]\n",
    "range2 = [19.3, 28.9]\n",
    "range3 = [28.9, 38.5]\n",
    "range4 = [38.5, 48.1]\n",
    "range5 = [48.1, 57.7]\n",
    "range6 = [57.7, 67.3]\n",
    "range7 = [67.3, 76.9]\n",
    "range8 = [76.9, 87]\n",
    "range9 = [87, 10000]\n",
    "df_range1 = df[(df['OC'] >= range1[0]) & (df['OC'] < range1[1])][\"Point_ID\"].values.tolist()\n",
    "df_range2 = df[(df['OC'] >= range2[0]) & (df['OC'] < range2[1])][\"Point_ID\"].values.tolist() \n",
    "df_range3 = df[(df['OC'] >= range3[0]) & (df['OC'] < range3[1])][\"Point_ID\"].values.tolist() \n",
    "df_range4 = df[(df['OC'] >= range4[0]) & (df['OC'] < range4[1])][\"Point_ID\"].values.tolist() \n",
    "df_range5 = df[(df['OC'] >= range5[0]) & (df['OC'] < range5[1])][\"Point_ID\"].values.tolist()\n",
    "df_range6 = df[(df['OC'] >= range6[0]) & (df['OC'] < range6[1])][\"Point_ID\"].values.tolist()\n",
    "df_range7 = df[(df['OC'] >= range7[0]) & (df['OC'] < range7[1])][\"Point_ID\"].values.tolist() \n",
    "df_range8 = df[(df['OC'] >= range8[0]) & (df['OC'] <= range8[1])][\"Point_ID\"].values.tolist()\n",
    "df_range9 = df[(df['OC'] >  range9[0]) & (df['OC']  < range9[1])][\"Point_ID\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range_list = [df_range1, df_range2, df_range3, df_range4, df_range5, df_range6, df_range7, df_range8, df_range9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7206\n",
      "3888\n",
      "2185\n",
      "1327\n",
      "867\n",
      "605\n",
      "415\n",
      "299\n",
      "1977\n"
     ]
    }
   ],
   "source": [
    "for df_range in df_range_list:\n",
    "    print(len(df_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26581954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_range1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_unwanted_tif_files(dir_path, file_list, remove_porb = 0.5):\n",
    "    file_list = [str(i) for i in file_list]\n",
    "    counter = 0\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".tif\"):\n",
    "                if  file.split('_')[0] in file_list:\n",
    "                    if random.random() < remove_porb:\n",
    "                        os.remove(os.path.join(root, file))\n",
    "                        counter += 1\n",
    "                        #print(\"Removed: \", file)\n",
    "    print(\"Total removed files: \", counter)\n",
    "    \n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "def duplicate_tif_files_n_times(dir_path, file_list, n):\n",
    "    file_list = [str(i) for i in file_list]\n",
    "    counter = 0\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".tif\"):\n",
    "                if file.split('_')[0] in file_list:\n",
    "                    for i in range(n):\n",
    "                        src_path = os.path.join(root, file)\n",
    "                        new_name = file.split('_')[0] + '_' + add_days_to_date(file.split('_')[1].split('.')[0], days=i+1) + '.tif'\n",
    "                        dst_path = os.path.join(root, new_name)\n",
    "                        shutil.copy2(src_path, dst_path)\n",
    "                        counter += 1\n",
    "                        #print(\"Duplicated: \", new_name)\n",
    "    print(\"Total duplicated files: \", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = ...# This the path to folder containing only training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total removed files:  3024\n",
      "Total removed files:  529\n",
      "Total duplicated files:  3120\n",
      "Total duplicated files:  1838\n",
      "Total duplicated files:  1794\n",
      "Total duplicated files:  2115\n",
      "Total duplicated files:  1680\n",
      "Total duplicated files:  1696\n"
     ]
    }
   ],
   "source": [
    "remove_unwanted_tif_files(train_path, df_range1, remove_porb = 0.6)\n",
    "remove_unwanted_tif_files(train_path, df_range2, remove_porb = 0.2)\n",
    "duplicate_tif_files_n_times(train_path, df_range3, 2)\n",
    "duplicate_tif_files_n_times(train_path, df_range4, 2)\n",
    "duplicate_tif_files_n_times(train_path, df_range5, 3)\n",
    "duplicate_tif_files_n_times(train_path, df_range6, 5)\n",
    "duplicate_tif_files_n_times(train_path, df_range7, 6)\n",
    "duplicate_tif_files_n_times(train_path, df_range8, 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove OC over 87 in the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = ... # Make sure it is the path to the whole dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total removed files:  4551\n"
     ]
    }
   ],
   "source": [
    "remove_unwanted_tif_files(dataset_path, df_range9, remove_porb = 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
