{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset_loader import SNDataset, SNDatasetClimate, myNormalize, myToTensor, Augmentations, RFTransform, TensorCenterPixels\n",
    "from torchvision import transforms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import date, datetime\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder called 'results' in the current directory if it doesn't exist\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name: D_2024_02_27_T_09_30\n",
      "Current Date and Time: 2024-02-27 09:30:06\n"
     ]
    }
   ],
   "source": [
    "# Format the date and time\n",
    "now = datetime.now()\n",
    "start_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "file_name = now.strftime(\"D_%Y_%m_%d_T_%H_%M\")\n",
    "print(\"File Name:\", file_name)\n",
    "print(\"Current Date and Time:\", start_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nafiseh'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "NAFISEH = \"Nafiseh\"\n",
    "MOIEN = \"Moien\"\n",
    "\n",
    "if \"d:\" in os.getcwd():\n",
    "    USER = MOIEN\n",
    "elif \"c:\" in os.getcwd():\n",
    "    USER = NAFISEH\n",
    "else:\n",
    "    raise Exception(\"Unknown user\")\n",
    "\n",
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OC_MAX = 87\n",
    "USE_CLIMATE = True\n",
    "USE_SRTM = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Normalization\n",
    "Random Forest doens't need normalization. So I addedthe RF transfom, it only reshapes the image into channels first format.\n",
    "then used myTransfomr to resize to 64x64.\n",
    "\n",
    "You can test my Normalize transform by uncommenting the line in the cell below.\n",
    "\n",
    "### Cut Center\n",
    "Cuts a 2x2 square from the center of the image.\n",
    "If `interplate_center_pixel` is set to True, then the center pixel is interpolated from the 4 surrounding pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mynorm = myNormalize(img_bands_min_max =[[(0,7),(0,1)], [(7,12),(-1,1)], [(12), (-4,2963)], [(13), (0, 90)]], oc_min = 0, oc_max = 200)\n",
    "rf_transform = RFTransform(oc_min = 0, oc_max = OC_MAX)\n",
    "my_to_tensor = myToTensor()\n",
    "cut_center = TensorCenterPixels(pixel_radius=1 ,interpolate_center_pixel = False)\n",
    "transform = transforms.Compose([rf_transform,my_to_tensor,cut_center])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bands to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [0,1,2,3,4,5,6,7,8,9,10,11] if not USE_SRTM else [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "########################################################################################\n",
    "################################# IF Not USE_CLIMATE ###############################\n",
    "########################################################################################\n",
    "\n",
    "if not USE_CLIMATE: # NOT USING THE CLIMATE DATA\n",
    "    if USER == MOIEN:\n",
    "        train_ds = SNDataset('D:\\python\\SoilNet\\dataset\\l8_images\\\\train\\\\','D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',l8_bands=bands, transform=transform)\n",
    "    elif USER == NAFISEH:\n",
    "        train_ds = SNDataset('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\l8_images\\\\train',\\\n",
    "                             'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\LUCAS_2015_all.csv',l8_bands=bands, transform=transform) #Nafiseh \n",
    "    if USER == MOIEN:\n",
    "        test_ds = SNDataset('D:\\python\\SoilNet\\dataset\\l8_images\\\\test\\\\','D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',\n",
    "                            l8_bands=bands, transform=transform, return_point_id=True)\n",
    "    elif USER == NAFISEH:\n",
    "        test_ds = SNDataset('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\l8_images\\\\test',\\\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\LUCAS_2015_all.csv',\n",
    "                            l8_bands=bands, transform=transform,return_point_id=True) #Nafiseh \n",
    "        \n",
    "########################################################################################\n",
    "################################### IF USE_CLIMATE #################################\n",
    "########################################################################################\n",
    "else: # USING THE CLIMATE DATA\n",
    "    if USER == MOIEN:\n",
    "        train_ds = SNDatasetClimate('D:\\python\\SoilNet\\dataset\\l8_images\\\\train\\\\',\n",
    "                                    'D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',\n",
    "                                    \"D:\\\\python\\\\SoilNet\\\\dataset\\\\Climate\\\\All\\\\filled\\\\\",\n",
    "                                    l8_bands=bands, transform=transform, normalize_climate = False)\n",
    "    elif USER == NAFISEH:\n",
    "        train_ds = SNDatasetClimate('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\l8_images\\\\train',\\\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\LUCAS_2015_all.csv',\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\Climate\\\\All\\\\filled',\n",
    "                            l8_bands=bands, transform=transform, normalize_climate = False) #Nafiseh \n",
    "    if USER == MOIEN:\n",
    "        test_ds = SNDatasetClimate('D:\\python\\SoilNet\\dataset\\l8_images\\\\test\\\\',\n",
    "                                'D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',\n",
    "                                \"D:\\\\python\\\\SoilNet\\\\dataset\\\\Climate\\\\All\\\\filled\\\\\",\n",
    "                                l8_bands=bands, transform=transform, normalize_climate = False, return_point_id=True)\n",
    "    elif USER == NAFISEH:\n",
    "        test_ds = SNDatasetClimate('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\l8_images\\\\test',\\\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\LUCAS_2015_all.csv',\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-3\\\\SoilNet\\\\dataset\\\\Climate\\\\All\\\\filled',\n",
    "                            l8_bands=bands, transform=transform, normalize_climate = False, return_point_id=True) #Nafiseh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 2, 2]), torch.Size([61, 11]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0][0].shape, train_ds[0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "NUM_WORKERS = 6 if USER == NAFISEH else 2\n",
    "TRAIN_BATCH_SIZE = 32 if USER == NAFISEH else 4\n",
    "TEST_BATCH_SIZE = 32 if USER == NAFISEH else 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_dl = DataLoader(test_ds, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CLIMATE:\n",
    "    # Preprocess the data using the DataLoader\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "    for batch_idx, (features, target) in enumerate(train_dl):\n",
    "        images_np = features[0].numpy()\n",
    "        climate_np = features[1].numpy()\n",
    "        # Preprocess the features as needed\n",
    "        images_processed = images_np.reshape(images_np.shape[0], -1) # Flatten the images with shape (batch_size, num_pixels * num_bands) -> e.g: (32, 4 * 12) if 4 pixel is being used or (32, 1 * 12) if 1 pixel is being used \n",
    "        climate_processed = climate_np.reshape(climate_np.shape[0], -1) # Flatten the climate data with shape (batch_size, num_climate_features * sequence_length) -> e.g: (32, 14*61) if 14 climate feature is being used and the each feature is a sequence of 61 months\n",
    "        features_processed = np.concatenate([images_processed, climate_processed], axis=1)\n",
    "        X_processed.append(features_processed)\n",
    "        y_processed.append(target.numpy())\n",
    "\n",
    "    X_processed = np.concatenate(X_processed, axis=0)  # (DataLoader Length, num_pixels * num_bands + num_climate_features * sequence_length)\n",
    "    y_processed = np.concatenate(y_processed, axis=0)  # (DataLoader Length,)\n",
    "else:\n",
    "    # Preprocess the data using the DataLoader\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "    for batch_idx, (features, target) in enumerate(train_dl):\n",
    "        features_np = features.numpy()\n",
    "        # Preprocess the features as needed\n",
    "        features_processed = features_np.reshape(features_np.shape[0], -1)\n",
    "        X_processed.append(features_processed)\n",
    "        y_processed.append(target.numpy())\n",
    "\n",
    "    X_processed = np.concatenate(X_processed, axis=0)\n",
    "    y_processed = np.concatenate(y_processed, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15296, 727) float32 | (15296,) float32\n",
      "Memory size of the Train array is 42.420166015625 MB or 0.04142594337463379 GB\n"
     ]
    }
   ],
   "source": [
    "print(X_processed.shape, X_processed.dtype,\"|\",y_processed.shape, y_processed.dtype)\n",
    "print(f\"Memory size of the Train array is {X_processed.nbytes/(1024**2)} MB or {X_processed.nbytes/(1024**3)} GB\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search.\n",
    "I don't know what are the best parameters for the random forest. <span style=\"color: green;\">Please change them and let me know what works best</span>. Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters to search over\n",
    "# param_dist = {\n",
    "#     # 'n_estimators': randint(30, 1000),\n",
    "#     'n_estimators': [1, 2, 5, 10, 20, 30, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
    "#     'max_depth': [1, 2, 3, 4, 5, 10],\n",
    "#     # 'max_features': [1.0, 'sqrt'],\n",
    "#     'min_samples_split': [1, 2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 5, 10, 15, 20],\n",
    "#     'max_leaf_nodes': [2, 5, 10, 15, 20],\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEEP SEARCH\n",
    "# param_grid = {\n",
    "#     'n_estimators': [10, 20, 30],\n",
    "#     'max_depth': [None, 5, 10, 20, 30],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'criterion': ['mse', 'mae'],\n",
    "#     'bootstrap': [True, False],\n",
    "#     'oob_score': [True, False],\n",
    "#     'max_samples': [0.5, 0.75, None],\n",
    "#     'max_leaf_nodes': [None, 10, 20],\n",
    "#     'min_impurity_decrease': [0.0, 0.1],\n",
    "#     'ccp_alpha': [0.0, 0.1],\n",
    "#     'warm_start': [True, False]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITTERS = 1 if USER == NAFISEH else 1\n",
    "CV = 2 if USER == NAFISEH else 2\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define RandomForestRegressor\n",
    "# rfr_ = RandomForestRegressor()\n",
    "# # Define the randomized search object\n",
    "# rfr = RandomizedSearchCV(\n",
    "#     estimator=rfr_,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=NUM_ITTERS, # Number of Combinations from the grid to try\n",
    "#     cv=CV, # Corss Validation Folds\n",
    "#     random_state=SEED\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Define RandomForestRegressor with the desired parameters\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators = 300,\n",
    "    max_depth = 10,\n",
    "    min_samples_split = 5,\n",
    "    min_samples_leaf = 20,\n",
    "    max_leaf_nodes = 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, max_leaf_nodes=20, min_samples_leaf=20,\n",
       "                      min_samples_split=5, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, max_leaf_nodes=20, min_samples_leaf=20,\n",
       "                      min_samples_split=5, n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, max_leaf_nodes=20, min_samples_leaf=20,\n",
       "                      min_samples_split=5, n_estimators=300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rfr.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a Random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point ID:  52944122 type:  <class 'str'>\n",
      "y_pred:  48.56009949370841 | y_true:  32.1\n"
     ]
    }
   ],
   "source": [
    "if USE_CLIMATE:\n",
    "    # Use the trained model to predict on a new image\n",
    "    n_rand = np.random.randint(0, len(test_ds))\n",
    "    new_image = test_ds[n_rand][0][0].numpy()\n",
    "    new_climate = test_ds[n_rand][0][1].numpy()\n",
    "    point_id = test_ds[n_rand][2]\n",
    "    print(\"Point ID: \", point_id, \"type: \", type(point_id))\n",
    "    new_image_processed = new_image.reshape(1, -1)\n",
    "    new_climate_processed = new_climate.reshape(1, -1)\n",
    "    new_features_processed = np.concatenate([new_image_processed, new_climate_processed], axis=1)\n",
    "    y_pred = rfr.predict(new_features_processed)\n",
    "    print(\"y_pred: \", y_pred[0], \"|\" ,\"y_true: \", test_ds[n_rand][1].numpy())\n",
    "else:\n",
    "    # Use the trained model to predict on a new image\n",
    "    n_rand = np.random.randint(0, len(test_ds))\n",
    "    new_image = test_ds[n_rand][0].numpy()\n",
    "    new_image_processed = new_image.reshape(1, -1)\n",
    "    y_pred = rfr.predict(new_image_processed)\n",
    "    point_id = test_ds[n_rand][2]\n",
    "    print(\"Point ID: \", point_id, \"type: \", type(point_id))\n",
    "    print(\"y_pred: \", y_pred[0], \"|\" ,\"y_true: \", test_ds[n_rand][1].numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CLIMATE:\n",
    "    # Preprocess the data using the DataLoader\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "    point_id_list = []\n",
    "    for batch_idx, (features, target,point_id) in enumerate(test_dl):\n",
    "        images_np = features[0].numpy()\n",
    "        climate_np = features[1].numpy()\n",
    "        \n",
    "        # Preprocess the features as needed\n",
    "        images_processed = images_np.reshape(images_np.shape[0], -1) # Flatten the images with shape (batch_size, num_pixels * num_bands) -> e.g: (32, 4 * 12) if 4 pixel is being used or (32, 1 * 12) if 1 pixel is being used \n",
    "        climate_processed = climate_np.reshape(climate_np.shape[0], -1) # Flatten the climate data with shape (batch_size, num_climate_features * sequence_length) -> e.g: (32, 14*61) if 14 climate feature is being used and the each feature is a sequence of 61 months\n",
    "        features_processed = np.concatenate([images_processed, climate_processed], axis=1)\n",
    "        X_processed.append(features_processed)\n",
    "        y_processed.append(target.numpy())\n",
    "        point_id_list = point_id_list + list(point_id)\n",
    "\n",
    "    X_processed = np.concatenate(X_processed, axis=0)  # (DataLoader Length, num_pixels * num_bands + num_climate_features * sequence_length)\n",
    "    y_processed = np.concatenate(y_processed, axis=0)  # (DataLoader Length,)\n",
    "else:\n",
    "    # Preprocess the data using the DataLoader\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "    point_id_list = []\n",
    "    for batch_idx, (features, target,point_id) in enumerate(test_dl):\n",
    "        features_np = features.numpy()\n",
    "        # Preprocess the features as needed\n",
    "        features_processed = features_np.reshape(features_np.shape[0], -1)\n",
    "        X_processed.append(features_processed)\n",
    "        y_processed.append(target.numpy())\n",
    "        point_id_list = point_id_list + list(point_id)\n",
    "\n",
    "    X_processed = np.concatenate(X_processed, axis=0)\n",
    "    y_processed = np.concatenate(y_processed, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_id_list = [int(i) for i in point_id_list]\n",
    "point_id_arr = np.array(point_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4371 4371 4371\n"
     ]
    }
   ],
   "source": [
    "print(len(point_id_arr), len(y_processed), len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 21.685791523723978\n",
      "MAE: 16.335132646669223\n"
     ]
    }
   ],
   "source": [
    "# RSME\n",
    "rmse = np.sqrt(mean_squared_error(y_processed, y_pred))\n",
    "print('RMSE:', rmse)\n",
    "# MAE\n",
    "mae = mean_absolute_error(y_processed, y_pred)\n",
    "print('MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save y_pred and y_true, point_id to a csv file\n",
    "df = pd.DataFrame({'point_id': point_id_list, 'y_true': y_processed, 'y_pred': y_pred})\n",
    "df.to_csv(f\"results/RF_{file_name}_{USER}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Date and Time: 2023-06-06 13:38:20\n"
     ]
    }
   ],
   "source": [
    "# Format the date and time\n",
    "now = datetime.now()\n",
    "finish_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"Finish Date and Time:\", finish_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m log_json[\u001b[39m'\u001b[39m\u001b[39mCV\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m CV\n\u001b[0;32m      9\u001b[0m log_json[\u001b[39m'\u001b[39m\u001b[39mSEED\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m SEED\n\u001b[1;32m---> 11\u001b[0m log_json[\u001b[39m'\u001b[39m\u001b[39mparam_dist\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(param_dist)\n\u001b[0;32m     12\u001b[0m log_json[\u001b[39m'\u001b[39m\u001b[39mBEST_PARAMS\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m rfr\u001b[39m.\u001b[39mbest_params_\n\u001b[0;32m     14\u001b[0m log_json[\u001b[39m'\u001b[39m\u001b[39mTIME\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m'\u001b[39m: start_string, \u001b[39m'\u001b[39m\u001b[39mfinish\u001b[39m\u001b[39m'\u001b[39m: finish_string}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'param_dist' is not defined"
     ]
    }
   ],
   "source": [
    "log_json = {}\n",
    "log_json['RMSE'] = rmse\n",
    "log_json['MAE'] = mae\n",
    "log_json['USE_CLIMATE'] = USE_CLIMATE\n",
    "log_json['USE_SRTM'] = USE_SRTM\n",
    "\n",
    "log_json['NUM_ITTERS'] = NUM_ITTERS\n",
    "log_json['CV'] = CV\n",
    "log_json['SEED'] = SEED\n",
    "\n",
    "log_json['param_dist'] = str(param_dist)\n",
    "log_json['BEST_PARAMS'] = rfr.best_params_\n",
    "\n",
    "log_json['TIME'] = {'start': start_string, 'finish': finish_string}\n",
    "\n",
    "log_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/RF_{file_name}_{USER}.json\", \"w\") as fp:\n",
    "    json.dump(log_json, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
