{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moi3n\\miniconda3\\envs\\pytorchGPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train_utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset_loader import SNDataset, SNDatasetClimate, myNormalize, myToTensor, Augmentations, RFTransform, TensorCenterPixels\n",
    "from torchvision import transforms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moien'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "NAFISEH = \"Nafiseh\"\n",
    "MOIEN = \"Moien\"\n",
    "\n",
    "if \"d:\" in os.getcwd():\n",
    "    USER = MOIEN\n",
    "elif \"c:\" in os.getcwd():\n",
    "    USER = NAFISEH\n",
    "else:\n",
    "    raise Exception(\"Unknown user\")\n",
    "\n",
    "USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CLIMATE = True\n",
    "USE_SRTM = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Normalization\n",
    "Random Forest doens't need normalization. So I addedthe RF transfom, it only reshapes the image into channels first format.\n",
    "then used myTransfomr to resize to 64x64.\n",
    "\n",
    "You can test my Normalize transform by uncommenting the line in the cell below.\n",
    "\n",
    "### Cut Center\n",
    "Cuts a 2x2 square from the center of the image.\n",
    "If `interplate_center_pixel` is set to True, then the center pixel is interpolated from the 4 surrounding pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mynorm = myNormalize(img_bands_min_max =[[(0,7),(0,1)], [(7,12),(-1,1)], [(12), (-4,2963)], [(13), (0, 90)]], oc_min = 0, oc_max = 200)\n",
    "rf_transform = RFTransform()\n",
    "my_to_tensor = myToTensor()\n",
    "cut_center = TensorCenterPixels(pixel_radius=1 ,interpolate_center_pixel=True)\n",
    "transform = transforms.Compose([rf_transform,my_to_tensor,cut_center])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bands to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [0,1,2,3,4,5,6,7,8,9,10,11] if not USE_SRTM else [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "########################################################################################\n",
    "################################# IF Not USE_LSTM_BRANCH ###############################\n",
    "########################################################################################\n",
    "\n",
    "if not USE_CLIMATE: # NOT USING THE CLIMATE DATA\n",
    "    if USER == MOIEN:\n",
    "        train_ds = SNDataset('D:\\python\\SoilNet\\dataset\\l8_images\\\\train\\\\','D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',l8_bands=bands, transform=transform)\n",
    "    elif USER == NAFISEH:\n",
    "        train_ds = SNDataset('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\l8_images\\\\train',\\\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\LUCAS_2015_all.csv',l8_bands=bands, transform=transform) #Nafiseh \n",
    "    if USER == MOIEN:\n",
    "        test_ds = SNDataset('D:\\python\\SoilNet\\dataset\\l8_images\\\\test\\\\','D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',l8_bands=bands, transform=transform)\n",
    "    elif USER == NAFISEH:\n",
    "        test_ds = SNDataset('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\l8_images\\\\test',\\\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\LUCAS_2015_all.csv',l8_bands=bands, transform=transform) #Nafiseh \n",
    "        \n",
    "########################################################################################\n",
    "################################### IF USE_LSTM_BRANCH #################################\n",
    "########################################################################################\n",
    "else: # USING THE CLIMATE DATA\n",
    "    if USER == MOIEN:\n",
    "        train_ds = SNDatasetClimate('D:\\python\\SoilNet\\dataset\\l8_images\\\\train\\\\',\n",
    "                                    'D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',\n",
    "                                    \"D:\\\\python\\\\SoilNet\\\\dataset\\\\Climate\\\\All\\\\filled\\\\\",\n",
    "                                    l8_bands=bands, transform=transform)\n",
    "    elif USER == NAFISEH:\n",
    "        train_ds = SNDatasetClimate('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\l8_images\\\\train',\\\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\LUCAS_2015_all.csv'\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\Climate\\\\All\\\\filled',\n",
    "                            l8_bands=bands, transform=transform) #Nafiseh \n",
    "    if USER == MOIEN:\n",
    "        test_ds = SNDatasetClimate('D:\\python\\SoilNet\\dataset\\l8_images\\\\test\\\\',\n",
    "                                'D:\\python\\SoilNet\\dataset\\LUCAS_2015_all.csv',\n",
    "                                \"D:\\\\python\\\\SoilNet\\\\dataset\\\\Climate\\\\All\\\\filled\\\\\",\n",
    "                                l8_bands=bands, transform=transform)\n",
    "    elif USER == NAFISEH:\n",
    "        test_ds = SNDatasetClimate('C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\l8_images\\\\test',\\\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\LUCAS_2015_all.csv',\n",
    "                            'C:\\\\Users\\\\nkakhani\\\\_Multimodal\\\\SoilNet-1\\\\dataset\\\\Climate\\\\All\\\\filled',\n",
    "                            l8_bands=bands, transform=transform) #Nafiseh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 1, 1]), torch.Size([61, 14]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0][0].shape, train_ds[0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "NUM_WORKERS = 6 if USER == NAFISEH else 2\n",
    "TRAIN_BATCH_SIZE = 32 if USER == NAFISEH else 4\n",
    "TEST_BATCH_SIZE = 32 if USER == NAFISEH else 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_dl = DataLoader(test_ds, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data using the DataLoader\n",
    "X_processed = []\n",
    "y_processed = []\n",
    "for batch_idx, (features, target) in enumerate(train_dl):\n",
    "    images_np = features[0].numpy()\n",
    "    climate_np = features[1].numpy()\n",
    "    # Preprocess the features as needed\n",
    "    images_processed = images_np.reshape(images_np.shape[0], -1) # Flatten the images with shape (batch_size, num_pixels * num_bands) -> e.g: (32, 4 * 12) if 4 pixel is being used or (32, 1 * 12) if 1 pixel is being used \n",
    "    climate_processed = climate_np.reshape(climate_np.shape[0], -1) # Flatten the climate data with shape (batch_size, num_climate_features * sequence_length) -> e.g: (32, 14*61) if 14 climate feature is being used and the each feature is a sequence of 61 months\n",
    "    features_processed = np.concatenate([images_processed, climate_processed], axis=1)\n",
    "    X_processed.append(features_processed)\n",
    "    y_processed.append(target.numpy())\n",
    "\n",
    "X_processed = np.concatenate(X_processed, axis=0)  # (DataLoader Length, num_pixels * num_bands + num_climate_features * sequence_length)\n",
    "y_processed = np.concatenate(y_processed, axis=0)  # (DataLoader Length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 868) float32 | (52,) float32\n",
      "Memory size of the Train array is 0.17218017578125 MB or 0.00016814470291137695 GB\n"
     ]
    }
   ],
   "source": [
    "print(X_processed.shape, X_processed.dtype,\"|\",y_processed.shape, y_processed.dtype)\n",
    "print(f\"Memory size of the Train array is {X_processed.nbytes/(1024**2)} MB or {X_processed.nbytes/(1024**3)} GB\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search.\n",
    "I don't know what are the best parameters for the random forest. <span style=\"color: green;\">Please change them and let me know what works best</span>. Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters to search over\n",
    "param_dist = {\n",
    "    'n_estimators': randint(90, 100),\n",
    "    'max_depth': [10, 20, 30],\n",
    "    # 'max_features': [1.0, 'sqrt'],\n",
    "    # 'min_samples_split': randint(2, 10),\n",
    "    # 'min_samples_leaf': randint(1, 10)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEEP SEARCH\n",
    "# param_grid = {\n",
    "#     'n_estimators': [10, 20, 30],\n",
    "#     'max_depth': [None, 5, 10, 20, 30],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'criterion': ['mse', 'mae'],\n",
    "#     'bootstrap': [True, False],\n",
    "#     'oob_score': [True, False],\n",
    "#     'max_samples': [0.5, 0.75, None],\n",
    "#     'max_leaf_nodes': [None, 10, 20],\n",
    "#     'min_impurity_decrease': [0.0, 0.1],\n",
    "#     'ccp_alpha': [0.0, 0.1],\n",
    "#     'warm_start': [True, False]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RandomForestRegressor\n",
    "rfr_ = RandomForestRegressor()\n",
    "# Define the randomized search object\n",
    "rfr = RandomizedSearchCV(\n",
    "    estimator=rfr_,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=1, # Number of Combinations from the grid to try\n",
    "    cv=10, # Corss Validation Folds\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30],\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002C232F81EB0&gt;},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30],\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002C232F81EB0&gt;},\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002C232F81EB0>},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'n_estimators': 93}\n"
     ]
    }
   ],
   "source": [
    "print(rfr.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a Random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:  19.247312189430318 | y_true:  18.7\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to predict on a new image\n",
    "n_rand = np.random.randint(0, len(test_ds))\n",
    "new_image = test_ds[n_rand][0][0].numpy()\n",
    "new_climate = test_ds[n_rand][0][1].numpy()\n",
    "new_image_processed = new_image.reshape(1, -1)\n",
    "new_climate_processed = new_climate.reshape(1, -1)\n",
    "new_features_processed = np.concatenate([new_image_processed, new_climate_processed], axis=1)\n",
    "y_pred = rfr.predict(new_features_processed)\n",
    "print(\"y_pred: \", y_pred[0], \"|\" ,\"y_true: \", test_ds[n_rand][1].numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data using the DataLoader\n",
    "X_processed = []\n",
    "y_processed = []\n",
    "for batch_idx, (features, target) in enumerate(train_dl):\n",
    "    images_np = features[0].numpy()\n",
    "    climate_np = features[1].numpy()\n",
    "    # Preprocess the features as needed\n",
    "    images_processed = images_np.reshape(images_np.shape[0], -1) # Flatten the images with shape (batch_size, num_pixels * num_bands) -> e.g: (32, 4 * 12) if 4 pixel is being used or (32, 1 * 12) if 1 pixel is being used \n",
    "    climate_processed = climate_np.reshape(climate_np.shape[0], -1) # Flatten the climate data with shape (batch_size, num_climate_features * sequence_length) -> e.g: (32, 14*61) if 14 climate feature is being used and the each feature is a sequence of 61 months\n",
    "    features_processed = np.concatenate([images_processed, climate_processed], axis=1)\n",
    "    X_processed.append(features_processed)\n",
    "    y_processed.append(target.numpy())\n",
    "\n",
    "X_processed = np.concatenate(X_processed, axis=0)  # (DataLoader Length, num_pixels * num_bands + num_climate_features * sequence_length)\n",
    "y_processed = np.concatenate(y_processed, axis=0)  # (DataLoader Length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.9635462537634716\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_processed, y_pred))\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
